description: "NagiosLogParser configuration file"
version: "0.1"

# This is YAML. If you don't know about YAML, you need to know that spaces are used for indentation. Whitespace width defines sections

configurations:
   # We lean on YAML includes to define a base template
   # All checks referring to this base_config will inherent its parameters
   # As this block has no "message" attribute we assume this config cannot be called by Nagios. You can overwrite these attributes in 
   # extending configurations.

   # Also, note that this will be the name of the check, "base_config".
   base_config: &base
      # Path to your log file
      # Use an absolute path or assume it is in the current work directory
      logfile: ./testlog.log

      # Also, throw an unknown status if the log file change date is older than this time in either minutes (..m), hours (..h) or days (..d)
      stalealert: 60d

      # Optionally, throw an error if the logfile is a null file, for example, if you are alerting on the
      # result of a nightly cron job
      nullalert: true

      # And another sanity option, you can tell the script to throw an alert if the log file is too big (in megabytes)
      # This could prevent this check from consuming large amounts of resources in case of log file flooding
      sizealert: 1000

      # Next, you could filter based on a date / time field. This requires 3 fields:
      # - the date column of the log line, assuming a tab or space seperated file such as a access log. Comma seperate a second column if the
      #   the time is in another column, the script will concatenate them with a space
      # - the format of these dates in the loggile in quotes, using Python date format conventions.
      #   Seperate date and time with a space if they are in 2 columns
      #     https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior
      # - and finally, which to include in either minutes (<number>m), hours (h) or days (d)
      # Note that you can use datecolumn and dateformat in a template and dateage in a check
      datecolumn: 0,1
      dateformat: "%Y-%m-%d %H:%M:%S"
      dateage: 60d

      # A setup that would work with Nginx out of the box:
      #       datecolumn: 3
      #       dateformat: "[%d/%b/%Y:%H:%M:%S"
      # If set to true and parsing fails due to an unexpected value that could not be parsed, ignore that line. Otherwise, exit with a Nagios unknown message
      # I would suggest first testing with false to see if your logfiles can be fully parsed so an incorrect dateformat would not end up spooling through your
      # entire logfile with each check.
      # Defaults to true
      dateignoreerrors: false
      # This is somewhat of a hack. The log parser is ideal for single line access logs, but could in theory be used for multi-line logs. That means the
      # date and the filter expression you are looking for are not on the same line. In that case, enable this flag to search all lines for dates.
      # In theory, this would make things a little slower but that should not be an issue if using more recent dates OR smaller logfiles
      # Also, this implicitely sets the dateignoreerrors to true, as not every line contains a valid date
      datesearchall: false

   check_http500:
      <<: *base
      # A description label, unused in checking
      description: List the number of error messages on ExampleURL

      dateage: 10m

      # Filter lines, using a regular expression. This will count every line with a "500" in it so this might generate
      # some false positives if the response time is also 500ms for example. If you are not familiar with regex, just enter a word
      filter: 500

      # Here's a better count for HTTP 5xx errors using simple regex:
      # filter: \"\s5[0-1][0-9]\s

      ## !! Note that any configuration with a message attribute will be used as a check
      ## Configurations without a message attribute are considered templates.
      ## Not pretty, please suggest me a better YAML solution
      ##
      ## You can use some macros in the message:
      ## [RESULT] - the result of the count of the number of lines counted (using the filter)
      ## [LOGFILE] - name of the log file
      ## [DATEAGE] - prints the dateage field
      message: There were [RESULT] ExampleURL HTTP 500 error messages in the last [DATEAGE]

      warning:
        greaterthan: 30

        # Optional message, the base message will be used if none are her
        message: More than [RESULT] ExampleURL HTTP 500 messages in the last [DATEAGE]

      critical:
        greaterthan: 50
        # Optional message, the base message will be used if none are her
        message: More than [RESULT] ExampleURL HTTP 500 messages in the last [DATEAGE]

      # Add performancedata to the check result
      performancedata: true

   check_num_requests:
      <<: *base
      description: Show the number of ExampleURL requests per 2 minutes
      filter: ExampleURL
      message: Currently we have [RESULT] ExampleURL requests per [DATEAGE]
      critical:
         greaterthan: 100
         message: More than [RESULT] ExampleURL requests in the last [DATEAGE]
      performancedata: true
      dateage: 2m

   check_num_error_requests:
      <<: *base
      description: Show the number of failed ExampleURL requests per 5 minutes
      ## 2019-04-25      10:16:25        GET     - 127.0.0.1  -       /ExampleURL_v3r0  500
      filter: ExampleURL_v3r0\s+500
      message: Currently we have [RESULT] failed ExampleURL requests per [DATEAGE]
      critical:
         greaterthan: 10
         message: More than [RESULT] failed ExampleURL requests in the last [DATEAGE]
      performancedata: true
      dateage: 5m


   check_slow_exampleurl_response:
      <<: *base
      description: Show the number of requests running more than 10 secs in the last 10 minutes
      ## Here's a log line that would match this complicated filter:
      ## 2019-04-25      10:16:25        GET     - 127.0.0.1  -       /ExampleURL_v3r0  500     12.001
      ##                                                                                ^^^     ^^
      ## Note that last column, that's the response time as a float in seconds. We use the dot to figure out
      ## whole seconds.
      filter: (200|500)\s+[1-9][0-9]
      message: Currently we have [RESULT] slow requests per [DATEAGE]
      critical:
         greaterthan: 100
         message: More than [RESULT] slow requests in the last [DATEAGE]
      performancedata: true
      dateage: 10m

   check_avg_exampleurl_response:
    <<: *base
    description: Show the average response time in the last 10 minutes
    filter: ExampleURL
    ## This is a special use case. Point the avgcolumn to the column number of the response times
    ## For example, in this log format:
    ## 2019-04-25      10:16:25        GET     - 127.0.0.1  -       /ExampleURL_v3r0  500     12.001
    ## ..starting at 0, it is column 8, the 12.001
    avgcolumn: 8
    message: Currently response time average for ExampleURL requests is at [RESULT]
    critical:
       greaterthan: 10
       message: Average response time is over [RESULT]!
    performancedata: true
    dateage: 10m

   check_apache_500:
    logfile: ./apachetest.log
    ## Apache lines look like this:
    ## 127.0.0.1 - - [25/Apr/2019:15:15:53 -0800] "GET /test.html HTTP/1.1" 500 2869
    ## Note the space for the timezone. That's considered an additional column, we'll just ignore that
    filter: HTTP\/1\.1\"\s500
    message: Currently Apache error count - [RESULT]
    datecolumn: 3
    dateformat: "[%d/%b/%Y:%H:%M:%S"
    dateage: 60m